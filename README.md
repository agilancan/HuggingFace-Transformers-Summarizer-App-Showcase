# ðŸ§  Text Summarizer with Hugging Face Transformers & Gradio

An interactive web application for abstractive text summarization, powered by Hugging Face Transformers and deployed using Gradio. This project explores how state-of-the-art language models can distill long-form text into concise, informative summaries through a clean, accessible UI.

## ðŸš€ Project Overview

This application demonstrates an end-to-end NLP pipeline that leverages the **`google/pegasus-large`** modelâ€”one of the top-performing models for abstractive summarization. The interface allows users to input large blocks of text (such as news articles or blog posts) and receive coherent, high-quality summaries within seconds.

Key components include:

- Integration of the Hugging Face `transformers` library to access advanced summarization models.
- Customization of model parameters for fine-tuned output length and sampling behavior.
- Deployment using `Gradio` to provide a user-friendly, browser-accessible interface.
- Tokenizer optimization for efficient preprocessing on resource-limited devices.

## ðŸ§° Technologies Used

- **Python 3.10+**
- **Hugging Face Transformers** â€” for accessing pre-trained LLMs
- **Gradio** â€” to create and deploy the web UI
- **Google Pegasus Model** â€” `google/pegasus-large`, fine-tuned for summarization tasks
- **Tokenizer** â€” same tokenizer as model for consistency and performance optimization

## ðŸ” Why PEGASUS?

The `google/pegasus-large` model was selected for its cutting-edge approach to abstractive summarization, utilizing a unique pre-training strategy called **Gap Sentence Generation (GSG)**. During pre-training, key sentences are removed from long-form documents, and the model learns to reconstruct themâ€”teaching it to focus on essential content. It was later fine-tuned on real-world summarization datasets such as CNN/DailyMail, XSum, and WikiHow, which makes it highly effective for summarizing news and editorial content.

Unlike the default `sshleifer/distilbart-cnn-12-6` model, PEGASUS handles longer token sequences (up to 1024â€“2048 tokens) and provides more semantically rich summaries.

## âš™ï¸ Features

- âœï¸ Input free-form long text (e.g., news, articles, reports)
- âš¡ Summarize with `google/pegasus-large` using Hugging Face pipeline
- ðŸŽ›ï¸ Adjustable model parameters like `min_length`, `max_length`, and `do_sample`
- ðŸ§ª Fast testing in Jupyter + Gradio interface for real-time interaction
- ðŸ–¥ï¸ Built for lower-end machines, with performance considerations like tokenizer integration

## ðŸ“· Example Output

**Input:**

> â€œThe Toronto Raptors have decided to extend the contract of head coach RajakoviÄ‡ following a season of defensive improvements and signs of progress, despite a losing recordâ€¦â€

**Summary Output:**

> "The Raptors are retaining coach RajakoviÄ‡, citing his strong defensive schemes and potential despite recent losing seasons."

---

## ðŸ’¡ Key Learnings
- Learned to modify default model pipelines and integrate new models with custom tokenizers.
- Experimented with decoding strategies (greedy vs. beam search vs. sampling).
- Overcame hardware limitations (integrated GPU) by optimizing token lengths and minimizing latency.
- Built a clean Gradio UI from scratch that integrates smoothly with backend inference.
